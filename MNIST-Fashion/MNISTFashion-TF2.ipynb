{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNISTFashion-TF2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lwBoUy3pwOqu","colab_type":"text"},"source":["### Importación de Tensorflow"]},{"cell_type":"code","metadata":{"id":"WObO5QzEv7sw","colab_type":"code","outputId":"6d4f8e43-3539-4237-e1ea-d90c9ba5f021","executionInfo":{"status":"ok","timestamp":1584154421452,"user_tz":360,"elapsed":1382,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 2.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZvlHBqDKwTyR","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.preprocessing import OneHotEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TB-4LYkAwYUM","colab_type":"text"},"source":["### Importación de datos"]},{"cell_type":"code","metadata":{"id":"-UpIfijvwXej","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets.fashion_mnist import load_data\n","fashion_mnist = load_data()\n","\n","(x_train, y_train), (x_test, y_test) = fashion_mnist"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5EuFzrkwwe32","colab_type":"text"},"source":["### Verificando los datos de prueba"]},{"cell_type":"code","metadata":{"id":"uS-ByVk5wWkk","colab_type":"code","outputId":"65053923-1c11-48bc-c64a-74bf06c6520d","executionInfo":{"status":"ok","timestamp":1584154423739,"user_tz":360,"elapsed":2880,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000,)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"DiRgIMtnwjxW","colab_type":"code","outputId":"b00b12e3-a03f-4d66-86a3-bc753a717868","executionInfo":{"status":"ok","timestamp":1584154423740,"user_tz":360,"elapsed":2710,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"TbrhYWFOwlo4","colab_type":"code","outputId":"44b98ca3-0bea-4014-966b-16cec23685f8","executionInfo":{"status":"ok","timestamp":1584154423740,"user_tz":360,"elapsed":2527,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["imagendemo = x_train[0]\n","plt.imshow(imagendemo, cmap = 'gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fc9cb751ac8>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9Lch6FBqwngl","colab_type":"code","colab":{}},"source":["def image_matrix(img):\n","    print('\\n'.join([''.join(['{:4}'.format(int(round(item * 255))) for item in row]) \n","      for row in img]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hV-UqIWSwqOr","colab_type":"code","outputId":"645685ba-169c-48ba-d5e4-ed340c429c21","executionInfo":{"status":"ok","timestamp":1584154423742,"user_tz":360,"elapsed":1942,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["image_matrix(imagendemo)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0 255   0   0331518615   0   0 2551020   0   0   0   0 255 255   0\n","   0   0   0   0   0   0   0   0   0   0   0   0 765   0918034680323851581013770   0   0   0 255 7651020   0   0 765\n","   0   0   0   0   0   0   0   0   0   0   0   01530   02601052020448803417036720313655865   0   0   0   030602550   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   039525601805278545390272853978041055277951632058651963533150183603825\n","   0   0   0   0   0   0   0   0   0   0   0 255   0175955278556865555905508055080415653238530855311103723035955224404386016830\n","   0   0   0   0   0   0   0   0   0 255 255 255   05100059160591605941558395568655686554825543154182032385313654998058395   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   04666557375550805686558140599255788557120566105712056355568656247544115   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   04921558140555905431550490459005406053550538055431556865561006196551510   0\n","   0   0   0   0   0   0   0   0   0 255 765   03060558455610054060555904896043095578855304055590571205406057630502355329513260\n","   0   0   0   0   0   0   0   0   0   01530   025245622205661056100555905176550490563555482554315566105610062475303454258514280\n","   0   0   0   0   0   0   0   0   01020   0   0140256018058140586505814061200591605431555590568655967055335553355329523460   0\n","   0   0 255102015301785 510   0   0   0   0   0604355763055335568655661055845566105635555080568655839554825555906502519635   0\n","   0 765   0   0   0   0   0   0   0158103697552020581405278554315563555559053040538055559057120568655584554825571206222040545   0\n","   0   0   0   0459011220209102728548195581405610056610553355763051000522755380558650571205967044880479406375063240594156069054825   0\n","   01453547685530405712056355571205304052020545705304053295510004054562475492155253056865650256502556355596705635553805561005916062730   0\n"," 7655151058140571205635553805538055457052275522755227556100612002040038250650255839556355479403927048705535505202053295566105814057375   0\n","2499059415504905355056610583955839559670634955610049470548255533561455165751861527030298354284055845563555482555335568655686557120583957395\n","19125520205406052020492155227553805573755508047175502355253050490543156120049725578856247560945568655559054060532955661056100563555865017085\n","12240517654666549470543155023547175484504947048960515105457055845563555610060180573755508050745525304743046155451354386046155522755253029325\n","   0311105584549215456454360546665499805202053550543155278553805535505100049980494704870549725487055049048960448803978042585451355355023460\n","   0   018870481955406048705446254386044625461554717547940481954794049215504905202053295535505355053805479404794049470489605508043350   0\n"," 510   0   0   016830510005661060435609456171062730619656222056355561004921548705456454641046410461554488042330428402524514790   0   0\n","   0   0   0   0   0   0   010200155551122018360104558925   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WZOLXbI7zFpE","colab_type":"text"},"source":["## Preparando los datos para el entrenamiento\n","\n","La x debe ser convertida a un vector para que pueda ser procesada por la red perceptrón profunda "]},{"cell_type":"code","metadata":{"id":"IMHwh152wr0-","colab_type":"code","outputId":"eb0d59ed-bcdd-4aff-a79c-6ce202f96103","executionInfo":{"status":"ok","timestamp":1584154423743,"user_tz":360,"elapsed":1735,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train = x_train.reshape(-1, 28 * 28).astype('float32')\n","x_test = x_test.reshape(-1, 28 * 28).astype('float32')\n","x_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 784)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"hxlXFkFkwzx7","colab_type":"code","outputId":"556b19b9-c391-4ef0-e0e0-efa028ccf148","executionInfo":{"status":"ok","timestamp":1584154423743,"user_tz":360,"elapsed":1588,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["x_train"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"YA46NuqYwuwr","colab_type":"text"},"source":["Normalizar los datos [0, 1] para aumentar la velocidad de entrenamiento."]},{"cell_type":"code","metadata":{"id":"NP-ZRjQ439Fu","colab_type":"code","colab":{}},"source":["x_train = x_train / 255.0\n","x_test = x_test / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1bqZLZMw56I","colab_type":"text"},"source":["Las salidas y deben se codificadas en one hot"]},{"cell_type":"code","metadata":{"id":"jt9NRYJAw1Vp","colab_type":"code","outputId":"11ebf5d9-1aa2-4323-af14-334086a625f9","executionInfo":{"status":"ok","timestamp":1584154424647,"user_tz":360,"elapsed":2132,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Onehot encode\n","onehot_encoder = OneHotEncoder(sparse = False)\n","y_train = y_train.reshape(len(y_train), 1)\n","y_train_onehot = onehot_encoder.fit_transform(y_train)\n","\n","y_test = y_test.reshape(len(y_test), 1)\n","y_test_onehot = onehot_encoder.fit_transform(y_test)\n","\n","y_train_onehot.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 10)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"ydARdOP_xBT8","colab_type":"text"},"source":["### Declarando la arquitectura\n","\n","Generando función "]},{"cell_type":"code","metadata":{"id":"cyLEoZW-w3kD","colab_type":"code","colab":{}},"source":["class DNN_model(object):\n","  def __init__(self,\n","               n_nodes_hl1 = 1024,\n","               n_nodes_hl2 = 512,\n","               n_nodes_hl3 = 256,\n","               n_nodes_hl4 = 128,\n","               n_classes = 10):\n","    self.h1LW = tf.Variable(np.random.rand(784, n_nodes_hl1), name = \"hl1weigths\", dtype = \"float32\")\n","    self.h1LB = tf.Variable(np.random.rand(n_nodes_hl1), name = \"hl1bias\", dtype = \"float32\")\n","\n","    self.h2LW = tf.Variable(np.random.rand(n_nodes_hl1, n_nodes_hl2), name = \"hl2weigths\", dtype = \"float32\")\n","    self.h2LB = tf.Variable(np.random.rand(n_nodes_hl2), name = \"hl2bias\", dtype = \"float32\")\n","\n","    self.h3LW = tf.Variable(np.random.rand(n_nodes_hl2, n_nodes_hl3), name = \"hl3weigths\", dtype = \"float32\")\n","    self.h3LB = tf.Variable(np.random.rand(n_nodes_hl3), name = \"hl3bias\", dtype = \"float32\")\n","\n","    self.h4LW = tf.Variable(np.random.rand(n_nodes_hl3, n_nodes_hl4), name = \"hl4weigths\", dtype = \"float32\")\n","    self.h4LB = tf.Variable(np.random.rand(n_nodes_hl4), name = \"hl4bias\", dtype = \"float32\")\n","\n","    self.outW = tf.Variable(np.random.rand(n_nodes_hl4, n_classes), name = \"outweigths\", dtype = \"float32\")\n","    self.outB = tf.Variable(np.random.rand(n_classes), name = \"outbias\", dtype = \"float32\")\n","\n","    self.trainable_variables =[self.h1LW, self.h1LB, self.h2LW, self.h2LB, self.h3LW, self.h3LB, self.h4LW, self.h4LB, self.outW, self.outB]      \n","        \n","  def __call__(self,x): \n","      # Declarando la arquitectura\n","      l1 = tf.add(tf.matmul(x, self.h1LW), self.h1LB)\n","      l1 = tf.nn.relu(l1)\n","\n","      l2 = tf.add(tf.matmul(l1, self.h2LW), self.h2LB)\n","      l2 = tf.nn.relu(l2)\n","\n","      l3 = tf.add(tf.matmul(l2, self.h3LW), self.h3LB)\n","      l3 = tf.nn.relu(l3)\n","\n","      l4 = tf.add(tf.matmul(l3, self.h4LW), self.h4LB)\n","      l4 = tf.nn.relu(l4)\n","\n","      output = tf.matmul(l4, self.outW) + self.outB\n","      return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SB_ocuTDRpm2","outputId":"5e1414f7-6951-488a-d09c-03bcdc87a7d4","executionInfo":{"status":"ok","timestamp":1584154424895,"user_tz":360,"elapsed":2015,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["DNN = DNN_model()\n","DNN(x_train[24:30])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(6, 10), dtype=float32, numpy=\n","array([[1.92954188e+11, 1.87330019e+11, 1.84199676e+11, 1.81201338e+11,\n","        1.85269600e+11, 1.89167141e+11, 1.88126724e+11, 2.00019411e+11,\n","        1.85279873e+11, 1.99400522e+11],\n","       [1.41006848e+11, 1.36896831e+11, 1.34609224e+11, 1.32418118e+11,\n","        1.35391101e+11, 1.38239345e+11, 1.37479045e+11, 1.46169987e+11,\n","        1.35398638e+11, 1.45717690e+11],\n","       [1.58819107e+11, 1.54189890e+11, 1.51613342e+11, 1.49145420e+11,\n","        1.52493982e+11, 1.55702018e+11, 1.54845659e+11, 1.64634444e+11,\n","        1.52502452e+11, 1.64125032e+11],\n","       [2.33581920e+11, 2.26773565e+11, 2.22984077e+11, 2.19354431e+11,\n","        2.24279265e+11, 2.28997464e+11, 2.27737993e+11, 2.42134794e+11,\n","        2.24291750e+11, 2.41385538e+11],\n","       [1.28326566e+11, 1.24586156e+11, 1.22504282e+11, 1.20510202e+11,\n","        1.23215839e+11, 1.25807952e+11, 1.25116006e+11, 1.33025399e+11,\n","        1.23222688e+11, 1.32613784e+11],\n","       [2.02121511e+11, 1.96230152e+11, 1.92951058e+11, 1.89810278e+11,\n","        1.94071822e+11, 1.98154535e+11, 1.97064688e+11, 2.09522426e+11,\n","        1.94082603e+11, 2.08874111e+11]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"aDrsTi04x6p4","colab_type":"text"},"source":["Seleccionar un optimizador "]},{"cell_type":"code","metadata":{"id":"1skjGUXfx1v3","colab_type":"code","colab":{}},"source":["#Adam Optimizer\n","optimizador = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xadZVhbyAvW","colab_type":"text"},"source":["### Definir las metricas a usar"]},{"cell_type":"code","metadata":{"id":"3yltF7JCx_5i","colab_type":"code","colab":{}},"source":["#Metricas: Media y Categorical Accuracy\n","train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n","train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n","test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"506fghB5yQt1","colab_type":"text"},"source":["### Calculo de gradientes y ajuste "]},{"cell_type":"code","metadata":{"id":"U5y-qGYTyN7V","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(model, tdata, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(tdata)\n","    #Funcion de error: Softmax Cross Entropy\n","    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n","   \n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  capped_grads_and_vars = [(grad,model.trainable_variables[index]) for index, grad in enumerate(gradients)]\n","  optimizador.apply_gradients(capped_grads_and_vars)\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DohX8vI-yZd9","colab_type":"code","colab":{}},"source":["@tf.function\n","def test_step(model,tdata, labels):\n","  predictions = model(tdata)\n","  #Funcion de error: Softmax Cross Entropy\n","  t_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bbl1Fogmyezy","colab_type":"text"},"source":["## función de entrenamiento  y prueba"]},{"cell_type":"code","metadata":{"id":"DjU1Dq6DybzF","colab_type":"code","colab":{}},"source":["def fitting(model, train_x, train_y, test_x, test_y, EPOCHS, N_batch, batch_size):\n","  for epoch in range(EPOCHS):\n","    i = 0\n","    while i + batch_size < len(train_x) or i + batch_size < batch_size * N_batch:\n","      start = i\n","      end = i + batch_size\n","      batch_x = train_x[start:end]\n","      batch_y = train_y[start:end]\n","      train_step(model, batch_x, batch_y)\n","      i += batch_size\n","\n","    test_step(model, test_x, test_y)\n","      \n","    template = 'Epoch {}, Perdida: {}, Exactitud: {}, Perdida de prueba: {}, Exactitud de prueba: {}'\n","    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100))\n","    \n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    test_loss.reset_states()\n","    test_accuracy.reset_states()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEPeNWVwy1Q7","colab_type":"code","outputId":"e093e933-c21d-406e-97cc-a06559dcdf2d","executionInfo":{"status":"ok","timestamp":1584155306213,"user_tz":360,"elapsed":103117,"user":{"displayName":"Enrique Ramos Diaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjaqx9qAqqhdgWN3SQirIlTkhYShPWzcDX3waCagw=s64","userId":"03180666184446923491"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["fitting(DNN, x_train, y_train_onehot, x_test, y_test_onehot, 100, 300, 100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1, Perdida: 0.07993095368146896, Exactitud: 97.59098052978516, Perdida de prueba: 3.9058022499084473, Exactitud de prueba: 86.08000183105469\n","Epoch 2, Perdida: 0.08252100646495819, Exactitud: 97.43238830566406, Perdida de prueba: 4.426830291748047, Exactitud de prueba: 86.30999755859375\n","Epoch 3, Perdida: 0.06366273015737534, Exactitud: 97.93822479248047, Perdida de prueba: 4.653422832489014, Exactitud de prueba: 86.29999542236328\n","Epoch 4, Perdida: 0.06568433344364166, Exactitud: 97.86310577392578, Perdida de prueba: 4.456965446472168, Exactitud de prueba: 85.95999908447266\n","Epoch 5, Perdida: 0.06440888345241547, Exactitud: 97.89983367919922, Perdida de prueba: 4.696976661682129, Exactitud de prueba: 85.41999816894531\n","Epoch 6, Perdida: 0.07103408873081207, Exactitud: 97.7412338256836, Perdida de prueba: 5.022397041320801, Exactitud de prueba: 86.06999969482422\n","Epoch 7, Perdida: 0.06917669624090195, Exactitud: 97.84474182128906, Perdida de prueba: 5.18248987197876, Exactitud de prueba: 86.2699966430664\n","Epoch 8, Perdida: 0.06219705194234848, Exactitud: 97.99331665039062, Perdida de prueba: 5.627236843109131, Exactitud de prueba: 86.3499984741211\n","Epoch 9, Perdida: 0.09345626085996628, Exactitud: 97.24540710449219, Perdida de prueba: 4.483979225158691, Exactitud de prueba: 85.57999420166016\n","Epoch 10, Perdida: 0.07076458632946014, Exactitud: 97.83972930908203, Perdida de prueba: 3.116657257080078, Exactitud de prueba: 86.13999938964844\n","Epoch 11, Perdida: 0.09450739622116089, Exactitud: 97.13188171386719, Perdida de prueba: 3.551837205886841, Exactitud de prueba: 86.00999450683594\n","Epoch 12, Perdida: 0.10054020583629608, Exactitud: 97.00167083740234, Perdida de prueba: 4.099668979644775, Exactitud de prueba: 86.22999572753906\n","Epoch 13, Perdida: 0.06963732093572617, Exactitud: 97.8030014038086, Perdida de prueba: 4.120388507843018, Exactitud de prueba: 86.18999481201172\n","Epoch 14, Perdida: 0.06697031855583191, Exactitud: 97.91485595703125, Perdida de prueba: 4.1428632736206055, Exactitud de prueba: 85.83999633789062\n","Epoch 15, Perdida: 0.07748239487409592, Exactitud: 97.67779541015625, Perdida de prueba: 3.978022575378418, Exactitud de prueba: 85.93000030517578\n","Epoch 16, Perdida: 0.0613119937479496, Exactitud: 98.08514404296875, Perdida de prueba: 4.114738464355469, Exactitud de prueba: 86.11000061035156\n","Epoch 17, Perdida: 0.0819530338048935, Exactitud: 97.5041732788086, Perdida de prueba: 4.274726390838623, Exactitud de prueba: 86.27999877929688\n","Epoch 18, Perdida: 0.06705647706985474, Exactitud: 97.92153930664062, Perdida de prueba: 4.6382365226745605, Exactitud de prueba: 85.97999572753906\n","Epoch 19, Perdida: 0.08123164623975754, Exactitud: 97.50083923339844, Perdida de prueba: 4.633444309234619, Exactitud de prueba: 86.41999816894531\n","Epoch 20, Perdida: 0.06386949121952057, Exactitud: 98.00834655761719, Perdida de prueba: 4.652703762054443, Exactitud de prueba: 86.1199951171875\n","Epoch 21, Perdida: 0.08032778650522232, Exactitud: 97.44574737548828, Perdida de prueba: 5.094042778015137, Exactitud de prueba: 86.25\n","Epoch 22, Perdida: 0.0829077959060669, Exactitud: 97.54591369628906, Perdida de prueba: 4.881070613861084, Exactitud de prueba: 85.94999694824219\n","Epoch 23, Perdida: 0.061506304889917374, Exactitud: 98.0567626953125, Perdida de prueba: 4.888784408569336, Exactitud de prueba: 86.11000061035156\n","Epoch 24, Perdida: 0.06372404098510742, Exactitud: 97.99331665039062, Perdida de prueba: 4.780639171600342, Exactitud de prueba: 86.44999694824219\n","Epoch 25, Perdida: 0.11304732412099838, Exactitud: 97.4424057006836, Perdida de prueba: 5.451305389404297, Exactitud de prueba: 86.0\n","Epoch 26, Perdida: 0.06773897260427475, Exactitud: 97.85643005371094, Perdida de prueba: 6.52993106842041, Exactitud de prueba: 85.87999725341797\n","Epoch 27, Perdida: 0.06431099027395248, Exactitud: 98.02503967285156, Perdida de prueba: 7.501994609832764, Exactitud de prueba: 85.98999786376953\n","Epoch 28, Perdida: 0.06579592078924179, Exactitud: 97.89816284179688, Perdida de prueba: 7.016164779663086, Exactitud de prueba: 85.50999450683594\n","Epoch 29, Perdida: 0.06387346237897873, Exactitud: 97.98497772216797, Perdida de prueba: 8.29482364654541, Exactitud de prueba: 86.44999694824219\n","Epoch 30, Perdida: 0.07545215636491776, Exactitud: 97.68280029296875, Perdida de prueba: 7.472175121307373, Exactitud de prueba: 85.97999572753906\n","Epoch 31, Perdida: 0.06747633963823318, Exactitud: 97.88314056396484, Perdida de prueba: 8.353227615356445, Exactitud de prueba: 86.58000183105469\n","Epoch 32, Perdida: 0.08033867180347443, Exactitud: 97.51585388183594, Perdida de prueba: 8.549932479858398, Exactitud de prueba: 86.54999542236328\n","Epoch 33, Perdida: 0.06826521456241608, Exactitud: 97.87145233154297, Perdida de prueba: 9.107657432556152, Exactitud de prueba: 86.37999725341797\n","Epoch 34, Perdida: 0.06734035164117813, Exactitud: 97.95492553710938, Perdida de prueba: 9.15748405456543, Exactitud de prueba: 86.6199951171875\n","Epoch 35, Perdida: 0.10185543447732925, Exactitud: 97.10517883300781, Perdida de prueba: 9.202325820922852, Exactitud de prueba: 85.80999755859375\n","Epoch 36, Perdida: 0.1169259250164032, Exactitud: 96.51251983642578, Perdida de prueba: 8.204446792602539, Exactitud de prueba: 86.75\n","Epoch 37, Perdida: 0.07071174681186676, Exactitud: 97.91819763183594, Perdida de prueba: 7.27672815322876, Exactitud de prueba: 86.27999877929688\n","Epoch 38, Perdida: 0.06536010652780533, Exactitud: 98.01502227783203, Perdida de prueba: 8.381223678588867, Exactitud de prueba: 86.3699951171875\n","Epoch 39, Perdida: 0.061820290982723236, Exactitud: 98.05509185791016, Perdida de prueba: 8.310961723327637, Exactitud de prueba: 86.55999755859375\n","Epoch 40, Perdida: 0.06821227073669434, Exactitud: 97.93154907226562, Perdida de prueba: 8.534455299377441, Exactitud de prueba: 86.36000061035156\n","Epoch 41, Perdida: 0.06823824346065521, Exactitud: 97.89315795898438, Perdida de prueba: 8.50611686706543, Exactitud de prueba: 86.65999603271484\n","Epoch 42, Perdida: 0.05684717372059822, Exactitud: 98.25375366210938, Perdida de prueba: 9.581808090209961, Exactitud de prueba: 85.86000061035156\n","Epoch 43, Perdida: 0.08933321386575699, Exactitud: 97.38063049316406, Perdida de prueba: 9.370636940002441, Exactitud de prueba: 86.37999725341797\n","Epoch 44, Perdida: 0.066469207406044, Exactitud: 97.93822479248047, Perdida de prueba: 9.362173080444336, Exactitud de prueba: 86.56999969482422\n","Epoch 45, Perdida: 0.06341131031513214, Exactitud: 98.05843353271484, Perdida de prueba: 9.693418502807617, Exactitud de prueba: 86.1199951171875\n","Epoch 46, Perdida: 0.06384813785552979, Exactitud: 98.061767578125, Perdida de prueba: 9.389735221862793, Exactitud de prueba: 86.44999694824219\n","Epoch 47, Perdida: 0.08472934365272522, Exactitud: 97.41902923583984, Perdida de prueba: 8.925411224365234, Exactitud de prueba: 86.1199951171875\n","Epoch 48, Perdida: 0.06945139914751053, Exactitud: 97.88814544677734, Perdida de prueba: 9.389657974243164, Exactitud de prueba: 86.4000015258789\n","Epoch 49, Perdida: 0.05895201861858368, Exactitud: 98.20533752441406, Perdida de prueba: 9.456269264221191, Exactitud de prueba: 86.66999816894531\n","Epoch 50, Perdida: 0.157132089138031, Exactitud: 97.48915100097656, Perdida de prueba: 3.8216440677642822, Exactitud de prueba: 85.70999908447266\n","Epoch 51, Perdida: 0.1056593507528305, Exactitud: 96.9131851196289, Perdida de prueba: 2.832658290863037, Exactitud de prueba: 86.3699951171875\n","Epoch 52, Perdida: 0.07489239424467087, Exactitud: 97.70783996582031, Perdida de prueba: 2.567138195037842, Exactitud de prueba: 86.25\n","Epoch 53, Perdida: 0.06747639179229736, Exactitud: 97.95826721191406, Perdida de prueba: 2.3093271255493164, Exactitud de prueba: 86.33000183105469\n","Epoch 54, Perdida: 0.05908437445759773, Exactitud: 98.2020034790039, Perdida de prueba: 2.52791690826416, Exactitud de prueba: 86.23999786376953\n","Epoch 55, Perdida: 0.0591706745326519, Exactitud: 98.25209045410156, Perdida de prueba: 3.0968451499938965, Exactitud de prueba: 86.08000183105469\n","Epoch 56, Perdida: 0.06471565365791321, Exactitud: 97.98664093017578, Perdida de prueba: 2.90356707572937, Exactitud de prueba: 86.27999877929688\n","Epoch 57, Perdida: 0.05962999165058136, Exactitud: 98.15525817871094, Perdida de prueba: 3.1527881622314453, Exactitud de prueba: 86.29999542236328\n","Epoch 58, Perdida: 0.06447229534387589, Exactitud: 98.01502227783203, Perdida de prueba: 3.16526460647583, Exactitud de prueba: 86.25\n","Epoch 59, Perdida: 0.07169214636087418, Exactitud: 97.83138275146484, Perdida de prueba: 3.3454015254974365, Exactitud de prueba: 86.48999786376953\n","Epoch 60, Perdida: 0.06922540068626404, Exactitud: 97.92487335205078, Perdida de prueba: 4.0103278160095215, Exactitud de prueba: 86.5\n","Epoch 61, Perdida: 0.05644214153289795, Exactitud: 98.2420654296875, Perdida de prueba: 3.5291671752929688, Exactitud de prueba: 86.23999786376953\n","Epoch 62, Perdida: 0.05745384842157364, Exactitud: 98.18363952636719, Perdida de prueba: 3.643389940261841, Exactitud de prueba: 86.26000213623047\n","Epoch 63, Perdida: 0.06496822088956833, Exactitud: 97.9699478149414, Perdida de prueba: 4.275923252105713, Exactitud de prueba: 86.54000091552734\n","Epoch 64, Perdida: 0.06900135427713394, Exactitud: 97.87145233154297, Perdida de prueba: 4.061743259429932, Exactitud de prueba: 86.08000183105469\n","Epoch 65, Perdida: 0.06765025854110718, Exactitud: 97.94824981689453, Perdida de prueba: 4.8292059898376465, Exactitud de prueba: 86.02999877929688\n","Epoch 66, Perdida: 0.07729757577180862, Exactitud: 97.701171875, Perdida de prueba: 4.071784496307373, Exactitud de prueba: 86.5\n","Epoch 67, Perdida: 0.06494203209877014, Exactitud: 97.97996520996094, Perdida de prueba: 4.771058082580566, Exactitud de prueba: 86.23999786376953\n","Epoch 68, Perdida: 0.05961292237043381, Exactitud: 98.1702880859375, Perdida de prueba: 4.6721649169921875, Exactitud de prueba: 86.0199966430664\n","Epoch 69, Perdida: 0.095993272960186, Exactitud: 97.31051635742188, Perdida de prueba: 2.50101900100708, Exactitud de prueba: 85.0\n","Epoch 70, Perdida: 0.08165957778692245, Exactitud: 97.52086639404297, Perdida de prueba: 2.57277250289917, Exactitud de prueba: 86.1199951171875\n","Epoch 71, Perdida: 0.08797961473464966, Exactitud: 97.39231872558594, Perdida de prueba: 3.872081756591797, Exactitud de prueba: 86.70999908447266\n","Epoch 72, Perdida: 0.061858028173446655, Exactitud: 98.12854766845703, Perdida de prueba: 4.53261137008667, Exactitud de prueba: 86.3499984741211\n","Epoch 73, Perdida: 0.05667583644390106, Exactitud: 98.27045440673828, Perdida de prueba: 4.514855861663818, Exactitud de prueba: 86.0\n","Epoch 74, Perdida: 0.05793013423681259, Exactitud: 98.2637710571289, Perdida de prueba: 4.859003067016602, Exactitud de prueba: 86.5\n","Epoch 75, Perdida: 0.06523130089044571, Exactitud: 98.02503967285156, Perdida de prueba: 4.602870941162109, Exactitud de prueba: 86.43000030517578\n","Epoch 76, Perdida: 0.07584547251462936, Exactitud: 97.7362289428711, Perdida de prueba: 5.406752109527588, Exactitud de prueba: 86.25\n","Epoch 77, Perdida: 0.07247845828533173, Exactitud: 97.93489074707031, Perdida de prueba: 5.922848224639893, Exactitud de prueba: 86.12999725341797\n","Epoch 78, Perdida: 0.0637359544634819, Exactitud: 98.07178497314453, Perdida de prueba: 6.951045989990234, Exactitud de prueba: 86.40999603271484\n","Epoch 79, Perdida: 0.05866175889968872, Exactitud: 98.21202087402344, Perdida de prueba: 7.0984930992126465, Exactitud de prueba: 86.12999725341797\n","Epoch 80, Perdida: 0.05447511747479439, Exactitud: 98.30551147460938, Perdida de prueba: 5.972017765045166, Exactitud de prueba: 86.04999542236328\n","Epoch 81, Perdida: 0.06661985069513321, Exactitud: 97.9432373046875, Perdida de prueba: 5.403520107269287, Exactitud de prueba: 86.5199966430664\n","Epoch 82, Perdida: 0.05756960064172745, Exactitud: 98.26210021972656, Perdida de prueba: 5.901797771453857, Exactitud de prueba: 86.08000183105469\n","Epoch 83, Perdida: 0.05617499724030495, Exactitud: 98.25375366210938, Perdida de prueba: 6.5640435218811035, Exactitud de prueba: 86.45999908447266\n","Epoch 84, Perdida: 0.05410894751548767, Exactitud: 98.33722686767578, Perdida de prueba: 8.034680366516113, Exactitud de prueba: 86.0999984741211\n","Epoch 85, Perdida: 0.07445124536752701, Exactitud: 97.88314056396484, Perdida de prueba: 7.7234063148498535, Exactitud de prueba: 86.40999603271484\n","Epoch 86, Perdida: 0.06747704744338989, Exactitud: 98.02003479003906, Perdida de prueba: 8.386765480041504, Exactitud de prueba: 86.44999694824219\n","Epoch 87, Perdida: 0.061227086931467056, Exactitud: 98.1402359008789, Perdida de prueba: 8.537647247314453, Exactitud de prueba: 86.29000091552734\n","Epoch 88, Perdida: 0.07084304094314575, Exactitud: 98.01836395263672, Perdida de prueba: 9.098615646362305, Exactitud de prueba: 86.11000061035156\n","Epoch 89, Perdida: 0.05571913719177246, Exactitud: 98.35225677490234, Perdida de prueba: 8.452912330627441, Exactitud de prueba: 86.30999755859375\n","Epoch 90, Perdida: 0.06119255721569061, Exactitud: 98.15192413330078, Perdida de prueba: 8.388559341430664, Exactitud de prueba: 86.48999786376953\n","Epoch 91, Perdida: 0.04973335191607475, Exactitud: 98.49415588378906, Perdida de prueba: 9.049843788146973, Exactitud de prueba: 86.55999755859375\n","Epoch 92, Perdida: 0.061590343713760376, Exactitud: 98.1185302734375, Perdida de prueba: 9.928997993469238, Exactitud de prueba: 86.19999694824219\n","Epoch 93, Perdida: 0.061291325837373734, Exactitud: 98.10684204101562, Perdida de prueba: 9.754685401916504, Exactitud de prueba: 86.12999725341797\n","Epoch 94, Perdida: 0.052641693502664566, Exactitud: 98.34724426269531, Perdida de prueba: 8.984993934631348, Exactitud de prueba: 86.58000183105469\n","Epoch 95, Perdida: 0.06758306175470352, Exactitud: 97.96827697753906, Perdida de prueba: 8.616800308227539, Exactitud de prueba: 86.38999938964844\n","Epoch 96, Perdida: 0.05193778872489929, Exactitud: 98.37228393554688, Perdida de prueba: 9.26581859588623, Exactitud de prueba: 86.43000030517578\n","Epoch 97, Perdida: 0.06247678026556969, Exactitud: 98.113525390625, Perdida de prueba: 9.112717628479004, Exactitud de prueba: 84.70999908447266\n","Epoch 98, Perdida: 0.07350637018680573, Exactitud: 97.80801391601562, Perdida de prueba: 8.55908489227295, Exactitud de prueba: 85.9000015258789\n","Epoch 99, Perdida: 0.06593213975429535, Exactitud: 97.98330688476562, Perdida de prueba: 7.931295394897461, Exactitud de prueba: 86.37999725341797\n","Epoch 100, Perdida: 0.07578763365745544, Exactitud: 97.762939453125, Perdida de prueba: 7.591053009033203, Exactitud de prueba: 86.33000183105469\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GS2m1TJh9_Ln","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}